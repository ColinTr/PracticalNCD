{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e4107f-3208-43a4-a6e5-8bfd9892fb73",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import adjusted_rand_score, normalized_mutual_info_score\n",
    "from iteration_utilities import random_combination\n",
    "from sklearn.cluster import KMeans\n",
    "from tqdm import tqdm\n",
    "import json\n",
    "\n",
    "from models.baseline_model import ArticleBaselineModel\n",
    "from models.tabularncd_model import TabularNCDModel\n",
    "from models.NCD_Spectral_Clustering import *\n",
    "from models.NCD_Kmeans import k_means_pp\n",
    "from models.PBN_model import PBNModel\n",
    "from src.dataset_utils import *\n",
    "from src.utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9eda0e0-4865-458b-93c5-f2f15aa16bcd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "import plotly.io as pio\n",
    "\n",
    "pio.renderers.default = 'iframe'  # So we can view the plots in the jupyter notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3de8d512-f5f5-42ce-9917-fa523a009a31",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afd3d9ae-6300-43ff-900d-39451eb3f7fa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "device = setup_device(use_cuda=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7236740a-2534-4942-b0a7-abce04824274",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_known_unknown_classes_splits(all_classes, n_unknown_classes, k_folds, random_seed=None):\n",
    "    \"\"\"\n",
    "    Select :k_folds: random combinations of :n_unknown_classes: from the given :all_classes:.\n",
    "    :param all_classes: the unique known classes where the probe classes will be selected from.\n",
    "    :param n_unknown_classes: ToDo.\n",
    "    :param k_folds: ToDo.\n",
    "    :param random_seed: ToDo.\n",
    "    \"\"\"\n",
    "    n_classes = len(all_classes)\n",
    "    number_of_possible_combinations = math.comb(n_classes, min(n_unknown_classes, n_classes))\n",
    "    \n",
    "    if k_folds == 0:\n",
    "        print(f\"k_folds set to 0, using the maximum number of possible combinations: {number_of_possible_combinations}\")\n",
    "        k_folds = number_of_possible_combinations\n",
    "    \n",
    "    # Sanity checks\n",
    "    if n_unknown_classes >= n_classes:\n",
    "        raise ValueError(f\"There are only {n_classes} known classes, cannot use {n_unknown_classes} classes as probe set for cross validation.\")\n",
    "    if k_folds > number_of_possible_combinations:\n",
    "        raise ValueError(f\"Not enough classes to have {k_folds} folds given {n_unknown_classes} unknown classes and {n_classes} total classes, the maximum is {number_of_possible_combinations}.\")\n",
    "    \n",
    "    if random_seed is not None:\n",
    "        random.seed(random_seed)\n",
    "    \n",
    "    # Select random combinations of unknown classes\n",
    "    selected_combinations = []\n",
    "    while len(selected_combinations) < k_folds:\n",
    "        new_combination = random_combination(all_classes, n_unknown_classes)\n",
    "        if new_combination not in selected_combinations:\n",
    "            selected_combinations.append(new_combination)\n",
    "            \n",
    "    # From these selected lists of unknown classes, create the known/unknown classes splits\n",
    "    known_classes_splits = []\n",
    "    unknown_classes_splits = []\n",
    "    for combination in selected_combinations:\n",
    "        unknown_classes_splits.append(list(combination))\n",
    "        known_classes_splits.append([known_class for known_class in all_classes if known_class not in list(combination)])\n",
    "    \n",
    "    return known_classes_splits, unknown_classes_splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62daa8d-fe62-4eb0-8e88-10b9c6da8e11",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def joint_shuffling(x, y, z=None):\n",
    "    np.random.seed(0)\n",
    "    p = np.random.permutation(len(x))\n",
    "    \n",
    "    if z is None:\n",
    "        return x[p], y[p], None\n",
    "    else:\n",
    "        return x[p], y[p], z[p]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "312e4124-cc15-4663-8926-b90b17d21db0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "dataset_names = ['HumanActivityRecognition', 'LetterRecognition', 'Pendigits', 'USCensus1990', 'multiple_feature', 'optdigits', 'cnae_9']\n",
    "\n",
    "dataset_name = 'USCensus1990'\n",
    "\n",
    "original_x_train, original_y_train, original_x_test, original_y_test = import_train_and_test_datasets(dataset_name)\n",
    "\n",
    "if dataset_name == 'USCensus1990':\n",
    "    # Too much train and test data, so we cap and balance them \n",
    "    train_indices_to_keep = []\n",
    "    for c in np.unique(original_y_train):\n",
    "        train_indices_to_keep += list(np.arange(len(original_y_train))[original_y_train == c][:1000])\n",
    "    train_indices_to_keep.sort()\n",
    "    original_x_train = original_x_train[train_indices_to_keep]\n",
    "    original_y_train = original_y_train[train_indices_to_keep]\n",
    "\n",
    "    test_indices_to_keep = []\n",
    "    for c in np.unique(original_y_test):\n",
    "        test_indices_to_keep += list(np.arange(len(original_y_test))[original_y_test == c][:1000])\n",
    "    test_indices_to_keep.sort()\n",
    "    original_x_test = original_x_test[test_indices_to_keep]\n",
    "    original_y_test = original_y_test[test_indices_to_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b41ec29c-c392-4d70-9038-59b102566414",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_kmeans_pred(n_clusters, x_train_unknown, x_test_unknown):\n",
    "    km = KMeans(n_clusters=n_clusters, init='random', n_init=10).fit(x_train_unknown.cpu().numpy())\n",
    "    return km.predict(x_test_unknown.cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2061bc0-f176-46b2-860a-08500c02d498",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_ncdkmeans_pred(n_clusters, x_train_known, y_train_known, x_train_unknown, x_test_unknown,):\n",
    "    # For this method, we define the centroids of the known classes with ground truth as initial centroids\n",
    "    known_classes_centroids = torch.stack([x_train_known[y_train_known==c].mean(axis=0) for c in np.unique(y_train_known)])\n",
    "    kmpp = k_means_pp(pre_centroids=known_classes_centroids, k_new_centroids=n_clusters)\n",
    "    kmpp.fit(x_train_unknown, tolerance=1e-4, n_iterations=300)\n",
    "    return kmpp.predict_unknown_data(x_test_unknown).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "523c6acb-63a5-49b8-b180-e9a3af6a995f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_sc_pred(n_new_clusters, x_test_unknown):\n",
    "    sc = ncd_spectral_clustering(n_new_clusters=n_new_clusters, min_dist=0.6)\n",
    "    return sc.fit_predict_simple(x_test_unknown)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b82769-47d5-4916-8034-cc0407a6efa8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_ncdsc_pred(n_clusters, test_unknown_spectral_embedding):\n",
    "    kmpp = k_means_pp(pre_centroids=None, k_new_centroids=n_clusters)\n",
    "    kmpp.fit(test_unknown_spectral_embedding, tolerance=1e-10, n_iterations=1000, n_init=10)\n",
    "    return kmpp.predict_unknown_data(test_unknown_spectral_embedding).cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5eaac1c-1ce7-4ce6-9215-93116cd5a40e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_baseline_pred(n_clusters, x_train_known, y_train_known, x_test_unknown, y_test_unknown, x_test_known, y_test_known):\n",
    "    base_config = {\n",
    "        'input_size': x_train_known.shape[1],\n",
    "        'hidden_layers_dims': [math.floor(3*x_train_known.shape[1]/4), math.floor(2*x_train_known.shape[1]/4)],\n",
    "        'activation_fct': 'relu',  # relu or sigmoid or tanh or None\n",
    "        'use_batchnorm': True,  # True or False\n",
    "        'use_norm': 'l2',  # None or 'l1' or 'l2'\n",
    "        'n_classes': len(np.unique(y_train_known)),\n",
    "        'n_clusters': n_clusters,\n",
    "        'clustering_model': 'kmeans',  # kmeans or ncd_kmeans or spectral_clustering or ncd_spectral_clustering\n",
    "        'clustering_runs': 1,  # To compute the average accuracy of the clustering\n",
    "        'batch_size': 512,\n",
    "        'epochs': 200,\n",
    "    }\n",
    "\n",
    "    # We load the hyperparameters that were optimized through grid search\n",
    "    d = json.load(open(\"hyperparameters.json\"))\n",
    "    config = d[\"Baseline\"][\"GT k\"][dataset_name]\n",
    "    # print(\"Using hyperparameters:\", config)\n",
    "\n",
    "    b_config = base_config.copy()\n",
    "    b_config.update(config)\n",
    "\n",
    "    model = ArticleBaselineModel(b_config).to(device)\n",
    "    losses_dict = model.train_on_known_classes(x_train_known=x_train_known, y_train_known=y_train_known,\n",
    "                                               x_test_unknown=x_test_unknown, y_test_unknown=y_test_unknown,\n",
    "                                               x_test_known=x_test_known, y_test_known=y_test_known,\n",
    "                                               batch_size=b_config['batch_size'], lr=b_config['lr'], epochs=b_config['epochs'], n_clusters=b_config['n_clusters'], clustering_runs=b_config['clustering_runs'],\n",
    "                                               evaluate=False, disable_tqdm=True)\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        y_test_unknown_pred = model.predict_new_data(b_config['n_clusters'], x_test_unknown)\n",
    "    \n",
    "    return y_test_unknown_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825da4fc-2b39-429d-8835-4286e19105dd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_pbn_pred(n_clusters, x_train, y_train, unknown_class_value, x_test_unknown, y_test_unknown, x_test_known, y_test_known):\n",
    "    base_config = {\n",
    "        'input_size': x_train.shape[1],\n",
    "        'hidden_layers_dims': [math.floor(3*x_train.shape[1]/4), math.floor(2*x_train.shape[1]/4)],\n",
    "        'activation_fct': 'relu',  # relu or sigmoid or tanh or None\n",
    "        'use_batchnorm': True,  # True or False\n",
    "        'use_norm': 'l2',  # None or 'l1' or 'l2'\n",
    "        'n_classes': len(np.unique(y_train)) - 1,\n",
    "        'clustering_model': 'kmeans',  # kmeans or ncd_kmeans or spectral_clustering or ncd_spectral_clustering\n",
    "        'clustering_runs': 1,  # To compute the average accuracy of the clustering\n",
    "        'batch_size': 512,\n",
    "        'epochs': 200,\n",
    "    }\n",
    "\n",
    "    # We load the hyperparameters that were optimized through grid search\n",
    "    d = json.load(open(\"hyperparameters.json\"))\n",
    "    config = d[\"PBN\"][\"GT k\"][dataset_name]\n",
    "    # print(\"Using hyperparameters:\", config)\n",
    "\n",
    "    pbn_config = base_config.copy()\n",
    "    pbn_config.update(config)\n",
    "\n",
    "    model = PBNModel(pbn_config).to(device)\n",
    "    losses_dict = model.train_on_known_classes(x_train=x_train, y_train=y_train, unknown_class_value=unknown_class_value,\n",
    "                                               x_test_unknown=x_test_unknown, y_test_unknown=y_test_unknown,\n",
    "                                               x_test_known=x_test_known, y_test_known=y_test_known,\n",
    "                                               batch_size=pbn_config['batch_size'], lr=pbn_config['lr'], epochs=pbn_config['epochs'], clustering_runs=pbn_config['clustering_runs'], w=pbn_config['w'],\n",
    "                                               evaluate=False, disable_tqdm=True)\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        y_test_unknown_pred = model.predict_new_data(n_clusters=n_clusters, x_unknown=x_test_unknown)\n",
    "    \n",
    "    return y_test_unknown_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe13351e-3a04-4786-8e6c-592374361ef1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def train_tabularncd(n_clusters, x_train, y_train, dataset_name, x_test_known, y_test_known, x_test_unknown, y_test_unknown, y_train_unknown, unknown_class_value):\n",
    "    base_config = {\n",
    "        'hidden_layers_dims': [math.floor(3*x_train.shape[1]/4), math.floor(2*x_train.shape[1]/4)],\n",
    "        'input_size': x_train.shape[1],\n",
    "        'n_known_classes': len(np.unique(y_train)),  # Takes into account the unknown class\n",
    "        'n_unknown_classes': n_clusters,\n",
    "        'activation_fct': 'relu',\n",
    "        'use_batchnorm': True,\n",
    "        'batch_size': 512,\n",
    "        'epochs': 200,\n",
    "        'M': 2000,\n",
    "    }\n",
    "    # We load the hyperparameters that were optimized through grid search\n",
    "    d = json.load(open(\"hyperparameters.json\"))\n",
    "    config = d[\"TabularNCD\"][\"GT k\"][dataset_name]\n",
    "    # print(\"Using hyperparameters:\", config)\n",
    "\n",
    "    tncd_config = base_config.copy()\n",
    "    tncd_config.update(config)\n",
    "\n",
    "    model = TabularNCDModel(tncd_config).to(device)\n",
    "    losses_dict = model.joint_training(config=tncd_config,\n",
    "                                       x_train=x_train, y_train=y_train,\n",
    "                                       x_test_known=x_test_known, y_test_known=y_test_known,\n",
    "                                       x_test_unknown=x_test_unknown, y_test_unknown=y_test_unknown,\n",
    "                                       y_train_unknown=y_train_unknown, unknown_class_value=unknown_class_value, disable_tqdm=True)\n",
    "    \n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        y_test_unknown_pred = model.clustering_head_forward(model.encoder_forward(x_test_unknown)).argmax(-1).cpu().numpy()\n",
    "    \n",
    "    return y_test_unknown_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab7ae90a-8115-4fa2-95f1-67b636792219",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_model_performance(model_name, n_runs,\n",
    "                          x_train, y_train, unknown_class_value,\n",
    "                          x_train_known, y_train_known,\n",
    "                          x_train_unknown, y_train_unknown,\n",
    "                          x_test_known, y_test_known,\n",
    "                          x_test_unknown, y_test_unknown,\n",
    "                          test_unknown_spectral_embedding, t):\n",
    "    \n",
    "    n_clusters = len(np.unique(y_train_unknown))\n",
    "    \n",
    "    accs, nmis, aris = [], [], []\n",
    "        \n",
    "    for i in range(n_runs):\n",
    "        t.set_postfix_str(\"run \" + str(i+1) + \" / \" + str(n_runs))\n",
    "        \n",
    "        if model_name == 'kmeans':\n",
    "            y_test_unknown_pred = get_kmeans_pred(n_clusters, x_train_unknown, x_test_unknown)\n",
    "        elif model_name == 'ncdkmeans':\n",
    "            y_test_unknown_pred = get_ncdkmeans_pred(n_clusters, x_train_known, y_train_known, x_train_unknown, x_test_unknown)\n",
    "        elif model_name == 'sc':\n",
    "            y_test_unknown_pred = get_sc_pred(n_clusters, x_test_unknown)\n",
    "        elif model_name == 'ncdsc':\n",
    "            y_test_unknown_pred = get_ncdsc_pred(n_clusters, test_unknown_spectral_embedding)\n",
    "        elif model_name == 'baseline':\n",
    "            y_test_unknown_pred = get_baseline_pred(n_clusters, x_train_known, y_train_known, x_test_unknown, y_test_unknown, x_test_known, y_test_known)\n",
    "        elif model_name == 'pbn':\n",
    "            y_test_unknown_pred = get_pbn_pred(n_clusters, x_train, y_train, unknown_class_value, x_test_unknown, y_test_unknown, x_test_known, y_test_known)\n",
    "        elif model_name == 'tabularncd':\n",
    "            y_test_unknown_pred = train_tabularncd(n_clusters, x_train, y_train, dataset_name, x_test_known, y_test_known, x_test_unknown, y_test_unknown, y_train_unknown, unknown_class_value)\n",
    "            \n",
    "        accs.append(hungarian_accuracy(y_test_unknown, y_test_unknown_pred))\n",
    "        nmis.append(normalized_mutual_info_score(y_test_unknown, y_test_unknown_pred))\n",
    "        aris.append(adjusted_rand_score(y_test_unknown, y_test_unknown_pred))\n",
    "        \n",
    "        t.update()\n",
    "        \n",
    "    return accs, nmis, aris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71ed53a0-0ba1-4b20-a4cf-e6dc218d4f8b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_model_perf_wrt_n_unknown_classes(classes_range, model_name, n_runs, k_folds):\n",
    "    \n",
    "    # In this case, we pre-compute the spectral embedding to avoid doing it every time\n",
    "    # Since it is deterministic, it should not be a problem\n",
    "    if model_name == 'ncdsc':\n",
    "        # We load the hyperparameters that were optimized through grid search\n",
    "        d = json.load(open(\"hyperparameters.json\"))\n",
    "        ncdsc_params = d[\"NCD SC\"][\"GT k\"][dataset_name]\n",
    "        # print(\"Using hyperparameters:\", ncdsc_params)\n",
    "\n",
    "        # Get the spectral embedding for all the data (since the hyperparameters are adapted for all the data, not only the novel data)\n",
    "        full_spectral_embedding = get_spectral_embedding(torch.tensor(original_x_test, dtype=torch.float, device=device), ncdsc_params['n_components'], ncdsc_params['min_dist'])\n",
    "    else:\n",
    "        full_spectral_embedding = None\n",
    "    \n",
    "    with tqdm(total = len(classes_range) * k_folds * n_runs) as t:\n",
    "    \n",
    "        accs_avg_1, nmis_avg_1, aris_avg_1 = [], [], []\n",
    "        accs_std_1, nmis_std_1, aris_std_1 = [], [], []\n",
    "        for n_unknown_classes in classes_range:\n",
    "\n",
    "            known_classes_splits, unknown_classes_splits = create_known_unknown_classes_splits(all_classes=np.unique(original_y_train), n_unknown_classes=n_unknown_classes, k_folds=k_folds, random_seed=0)\n",
    "\n",
    "            accs_avg_2, nmis_avg_2, aris_avg_2 = [], [], []\n",
    "            accs_std_2, nmis_std_2, aris_std_2 = [], [], []\n",
    "            for known_classes_split, unknown_classes_split in zip(known_classes_splits, unknown_classes_splits):\n",
    "                # print(f\"known_classes_split={known_classes_split}, unknown_classes_split={unknown_classes_split}\")\n",
    "\n",
    "                x_train, y_train, _ = joint_shuffling(original_x_train, original_y_train)\n",
    "                x_test, y_test, shuffled_full_spectral_embedding = joint_shuffling(original_x_test, original_y_test, full_spectral_embedding)\n",
    "                x_train, y_train, x_test, y_test, unknown_class_value, y_train_save, y_test_save = select_known_unknown_classes(x_train, y_train,\n",
    "                                                                                                                                x_test, y_test,\n",
    "                                                                                                                                known_classes=known_classes_split,\n",
    "                                                                                                                                unknown_classes=unknown_classes_split,\n",
    "                                                                                                                                silent=True)\n",
    "                \n",
    "                x_train = torch.tensor(x_train, dtype=torch.float, device=device)\n",
    "                x_test = torch.tensor(x_test, dtype=torch.float, device=device)\n",
    "\n",
    "                x_train_known = x_train[y_train != unknown_class_value]\n",
    "                x_train_unknown = x_train[y_train == unknown_class_value]\n",
    "                y_train_known = y_train[y_train != unknown_class_value]\n",
    "\n",
    "                x_test_known = x_test[y_test != unknown_class_value]\n",
    "                x_test_unknown = x_test[y_test == unknown_class_value]\n",
    "                y_test_known = y_test[y_test != unknown_class_value]\n",
    "\n",
    "                # For evaluation\n",
    "                y_train_unknown_save = y_train_save[y_train == unknown_class_value]\n",
    "                y_test_unknown_save = y_test_save[y_test == unknown_class_value]\n",
    "                y_train_unknown = np.array(pd.Series(y_train_unknown_save).astype('category').cat.codes)\n",
    "                y_test_unknown = np.array(pd.Series(y_test_unknown_save).astype('category').cat.codes)\n",
    "\n",
    "                # We need the targets to be in {0, ..., C^l} exactly\n",
    "                classifier_mapper, classifier_ind = np.unique(y_train_known, return_inverse=True)\n",
    "                classifier_mapping_dict = dict(zip(y_train_known, classifier_ind))\n",
    "\n",
    "                y_train_known = np.array(list(map(classifier_mapping_dict.get, y_train_known)))\n",
    "                y_test_known = np.array(list(map(classifier_mapping_dict.get, y_test_known)))\n",
    "\n",
    "                if model_name == 'ncdsc':\n",
    "                    test_unknown_spectral_embedding = shuffled_full_spectral_embedding[y_test == unknown_class_value]\n",
    "                else:\n",
    "                    test_unknown_spectral_embedding = None\n",
    "                \n",
    "                accs, nmis, aris = get_model_performance(model_name, n_runs,\n",
    "                                                         x_train, y_train, unknown_class_value,\n",
    "                                                         x_train_known, y_train_known,\n",
    "                                                         x_train_unknown, y_train_unknown,\n",
    "                                                         x_test_known, y_test_known,\n",
    "                                                         x_test_unknown, y_test_unknown,\n",
    "                                                         test_unknown_spectral_embedding, t)\n",
    "\n",
    "                accs_avg_2.append(np.mean(accs))\n",
    "                nmis_avg_2.append(np.mean(nmis))\n",
    "                aris_avg_2.append(np.mean(aris))\n",
    "                accs_std_2.append(np.std(accs))\n",
    "                nmis_std_2.append(np.std(nmis))\n",
    "                aris_std_2.append(np.std(aris))\n",
    "\n",
    "            accs_avg_1.append(np.mean(accs_avg_2))\n",
    "            nmis_avg_1.append(np.mean(nmis_avg_2))\n",
    "            aris_avg_1.append(np.mean(aris_avg_2))\n",
    "            accs_std_1.append(np.std(accs_std_2))\n",
    "            nmis_std_1.append(np.std(nmis_std_2))\n",
    "            aris_std_1.append(np.std(aris_std_2))\n",
    "            \n",
    "    return np.array(accs_avg_1), np.array(nmis_avg_1), np.array(aris_avg_1), np.array(accs_std_1), np.array(nmis_std_1), np.array(aris_std_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4aed883f-c77b-4b9b-a44f-ea11f4aaa6b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_perf_for_multiple_models(classes_range, model_names, n_runs , k_folds):\n",
    "    full_df = pd.DataFrame()\n",
    "    \n",
    "    unknown_class_share_list = np.array(classes_range) / len(np.unique(original_y_train))\n",
    "    \n",
    "    for model_name in model_names:\n",
    "        print(f\"Getting results for {model_name}...\")\n",
    "        accs_avg, nmis_avg, aris_avg, accs_std, nmis_std, aris_std = get_model_perf_wrt_n_unknown_classes(classes_range=classes_range, model_name=model_name, n_runs=n_runs, k_folds=k_folds)\n",
    "    \n",
    "        df = pd.DataFrame({\"unknown_class_share_list\": unknown_class_share_list, \"accs_avg\": accs_avg, \"accs_std\": accs_std, \"method\": np.repeat(model_name, len(accs_avg))})\n",
    "        \n",
    "        full_df = pd.concat([full_df, df])\n",
    "        full_df.to_csv(f'results_{dataset_name}.csv', index=False)\n",
    "        \n",
    "    return full_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48c2fde-5c0c-4ff7-be4b-0002ab5ffcc4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results_df = get_perf_for_multiple_models(classes_range = range(2, len(np.unique(original_y_train)) - 1),\n",
    "                                          model_names = ['kmeans', 'ncdkmeans', 'sc', 'ncdsc', 'baseline', 'pbn', 'tabularncd'],  # 'kmeans', 'ncdkmeans', 'sc', 'ncdsc', 'baseline', 'pbn', 'tabularncd'\n",
    "                                          n_runs = 5, k_folds = 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e406b2aa-c9a0-4498-8821-814353327253",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig = custom_line_with_error_fill(\n",
    "    data_frame = results_df,\n",
    "    x = 'unknown_class_share_list',\n",
    "    y = 'accs_avg',\n",
    "    error_y = 'accs_std',\n",
    "    error_y_mode = 'band', # Either `band` or `bar`.\n",
    "    color = 'method',\n",
    "    title = f'Results for {dataset_name} dataset',\n",
    "    markers = '.',\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b7de8e-c8f8-424b-bde0-3846f64c1f91",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fig = px.line(results_df, x=\"unknown_class_share_list\", y=\"accs_avg\", color='method', markers='.', title=f'Results for {dataset_name} dataset')\n",
    "fig.update_layout(xaxis_title=\"Share of unknown classes\", yaxis_title=\"Average accuracy\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d2998e7-94c9-4cd9-95b2-4cce49b45113",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "519cd303-0a34-451e-a991-ce3edddab784",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "results_df = pd.read_csv('results_LetterRecognition.csv')\n",
    "dataset_name = 'LetterRecognition'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c09c05-d040-4dca-9a43-4dae5185d3d1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8664dc-98de-4388-b9b5-e35a563842e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venvexploration",
   "language": "python",
   "name": "venvexploration"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
